apiVersion: apps/v1
kind: Deployment
metadata:
  name: end-to-end-pipeline
  labels:
    app: pipeline
spec:
  replicas: 1   # One pod to minimize cost
  selector:
    matchLabels:
      app: pipeline
  template:
    metadata:
      labels:
        app: pipeline
    spec:
      initContainers:
        - name: create-airflow-db
          image: postgres:14
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Checking if Airflow role exists..."
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com -U dandy -d postgres -tc "SELECT 1 FROM pg_roles WHERE rolname='airflow';" | grep -q 1 || \
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com -U dandy -d postgres -c "CREATE ROLE airflow WITH LOGIN PASSWORD 'airflow';"

              echo "Checking if Airflow DB exists..."
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com -U dandy -d postgres -tc "SELECT 1 FROM pg_database WHERE datname='airflow';" | grep -q 1 || \
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com -U dandy -d postgres -c "CREATE DATABASE airflow;"
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com -U dandy -d postgres -c "GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;"

          env:
            - name: PGPASSWORD
              value: "dandy123"

        - name: init-airflow-schema
          image: cutedandelion/airflow-pipeline:latest
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Running DB migration..."
              airflow db migrate
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://dandy:dandy123@data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com:5432/airflow"

      containers:
        # Airflow UI / DAG runner
        - name: airflow
          image: cutedandelion/airflow-pipeline:latest
          command: ["airflow", "standalone"]
          ports:
            - containerPort: 5000
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: "LocalExecutor"
            - name: AIRFLOW__CORE__LOAD_EXAMPLES
              value: "False"
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://dandy:dandy123@data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com:5432/airflow"
            - name: AIRFLOW__WEBSERVER__WEB_SERVER_HOST
              value: "0.0.0.0"
            - name: AIRFLOW__WEBSERVER__WEB_SERVER_PORT
              value: "8080"
            - name: AIRFLOW__API__HOST
              value: "0.0.0.0"
            - name: AIRFLOW__API__PORT
              value: "5000"
          volumeMounts:
            - name: airflow-logs
              mountPath: /opt/airflow/logs

        # Zookeeper for Kafka
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.5.11
          ports:
            - containerPort: 2181
          env:
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"

        # Kafka broker
        - name: kafka
          image: confluentinc/cp-kafka:7.5.11
          ports:
            - containerPort: 9092
          env:
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "localhost:2181"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://localhost:9092"

        # Kafka client - to run producer script
        - name: kafka-client
          image: python:3.10
          command: ["/bin/bash", "-c"]
          args:
            # Install kafka-python once, then sleep forever
            - |
              pip install --no-cache-dir kafka-python && \
              sleep infinity

        # Spark job runner
        - name: spark
          image: cutedandelion/spark-pipeline:latest
          ports:
            - containerPort: 4040
          env:
            - name: SPARK_UI_PORT
              value: "4040"
            - name: SPARK_MASTER_PORT
              value: "7077"

        # Dev storage
        - name: mongodb
          image: mongo:latest
          ports:
            - containerPort: 27017

        # Metrics DB
        - name: influxdb
          image: influxdb:latest
          ports:
            - containerPort: 8086

      # Volumes (simple and ephemeral)
      volumes:
        - name: airflow-logs
          emptyDir: {}
