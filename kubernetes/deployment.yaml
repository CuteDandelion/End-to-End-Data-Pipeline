apiVersion: apps/v1
kind: Deployment
metadata:
  name: end-to-end-pipeline
  labels:
    app: pipeline
spec:
  replicas: 1   # One pod to minimize cost
  selector:
    matchLabels:
      app: pipeline
  template:
    metadata:
      labels:
        app: pipeline
    spec:
      initContainers:
        - name: create-airflow-db
          image: postgres:14
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Checking if Airflow DB exists..."
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com \
                   -U dandy \
                   -p 5432 \
                   -d postgres \
                   -tc "SELECT 1 FROM pg_database WHERE datname='airflow';" | grep -q 1 || \
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com \
                   -U dandy \
                   -p 5432 \
                   -d postgres \
                   -c "DO \$\$ BEGIN IF NOT EXISTS (SELECT FROM pg_roles WHERE rolname='airflow') THEN CREATE ROLE airflow WITH LOGIN PASSWORD 'airflow'; END IF; END\$\$;" && \ 
              psql -h data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com \
                   -U dandy \
                   -p 5432 \
                   -d postgres \
                   -c "CREATE DATABASE airflow OWNER airflow;"
          env:
            - name: PGPASSWORD
              value: "dandy123"

        - name: init-airflow-schema
          image: cutedandelion/airflow-pipeline:latest
          command: ["/bin/bash", "-c"]
          args:
            - |
              airflow db init
              airflow users create \
                --username admin \
                --password admin \
                --firstname Admin \
                --lastname User \
                --role Admin \
                --email admin@example.com || true
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://dandy:dandy123@data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com:5432/airflow"

      containers:
        # Airflow UI / DAG runner
        - name: airflow
          image: cutedandelion/airflow-pipeline:latest
          ports:
            - containerPort: 8080
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: "LocalExecutor"
            - name: AIRFLOW__CORE__LOAD_EXAMPLES
              value: "False"
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://dandy:dandy123@data-pipeline-rds.cet8668qsrqm.us-east-1.rds.amazonaws.com:5432/airflow"
            - name: AIRFLOW__WEBSERVER__WEB_SERVER_HOST
              value: "0.0.0.0"
            - name: AIRFLOW__WEBSERVER__WEB_SERVER_PORT
              value: "8080"
          volumeMounts:
            - name: airflow-logs
              mountPath: /opt/airflow/logs

        # Zookeeper for Kafka
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.3.2
          ports:
            - containerPort: 2181
          env:
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"

        # Kafka broker
        - name: kafka
          image: confluentinc/cp-kafka:7.3.2
          ports:
            - containerPort: 9092
          env:
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "localhost:2181"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://localhost:9092"

        # Spark job runner
        - name: spark
          image: cutedandelion/spark-pipeline:latest
          ports:
            - containerPort: 4040

        # Dev storage
        - name: mongodb
          image: mongo:latest
          ports:
            - containerPort: 27017

        # Metrics DB
        - name: influxdb
          image: influxdb:latest
          ports:
            - containerPort: 8086

      # Volumes (simple and ephemeral)
      volumes:
        - name: airflow-logs
          emptyDir: {}
